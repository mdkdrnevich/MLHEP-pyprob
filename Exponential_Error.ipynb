{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot import dbm.gnu: No module named '_gdbm'\n",
      "\u001b[1m\u001b[31mWarning: Empirical distributions on disk may perform slow because GNU DBM is not available. Please install and configure gdbm library for Python for better speed.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pyprob\n",
    "from pyprob import Model\n",
    "from pyprob.distributions import Normal, Uniform, Categorical, Exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of leaves\n",
    "class MarkovChainTree(Model):\n",
    "    def __init__(self, depth=5):\n",
    "        super().__init__(name=\"Markov Chain Path\") # give the model a name\n",
    "        self.depth = depth\n",
    "\n",
    "    def forward(self): # Needed to specify how the generative model is run forward\n",
    "        # sample the (latent) mean variable to be inferred:\n",
    "        paths = [[0,],]  # up to 2^d-1 long list of the full paths for each 'particle'\n",
    "        moves = {0: -1, 1: 1}\n",
    "        for i in range(self.depth):\n",
    "            for j in range(len(paths)):\n",
    "                coord = paths[j][-1]\n",
    "                #splitting = pyprob.sample(Normal(0,1), name = 'split{}{}'.format(i,j))\n",
    "                #if splitting.item() < -1:\n",
    "                splitting = pyprob.sample(Exponential(1.5), name = 'split{}{}'.format(i,j))\n",
    "                if splitting < 0.2:\n",
    "                    move = pyprob.sample(Categorical([1/2.,1/2.]), name = 'input_split{}{}'.format(i,j))\n",
    "                    move = moves[move.item()]\n",
    "                    new_path = paths[j].copy()\n",
    "                    new_path.append(coord + move)\n",
    "                    paths.append(new_path)\n",
    "                move = pyprob.sample(Categorical([1/2.,1/2.]), name = 'input{}{}'.format(i,j))\n",
    "                move = moves[move.item()]\n",
    "                paths[j].append(coord + move)\n",
    "\n",
    "        obs_distr = Normal(len(paths), 0.3)\n",
    "        pyprob.observe(obs_distr, name='obs0') # NOTE: observe -> denotes observable variables\n",
    "        return paths\n",
    "\n",
    "model = MarkovChainTree(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 0, -1, -2, -3, -2],\n",
       " [0, 1, 0, -1, 0, -1, 0],\n",
       " [0, 1, 0, -1, -2, -3, -2],\n",
       " [0, 1, 0, 1, 2, 3, 2],\n",
       " [0, 1, 0, -1, -2, -1, -2],\n",
       " [0, 1, 0, -1, -2, -3, -2],\n",
       " [0, 1, 0, -1, 0, -1, -2],\n",
       " [0, 1, 0, -1, -2, -3, -2],\n",
       " [0, 1, 0, 1, 2, 3, 4]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new inference network...\n",
      "Observable obs0: reshape not specified, using shape torch.Size([]).\n",
      "Observable obs0: using embedding dim torch.Size([100]).\n",
      "Observable obs0: observe embedding not specified, using the default FEEDFORWARD.\n",
      "Observable obs0: using embedding depth 5.\n",
      "Observe embedding dimension: 100\n",
      "Train. time | Epoch| Trace     | Init. loss| Min. loss | Curr. loss| T.since min | Learn.rate| Traces/sec\n",
      "New layers, address: 86__forward__splitting__Exponential__1, distribution: Exponential\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Distribution currently unsupported: Exponential",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6abe42d5c825>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model.learn_inference_network(\n\u001b[1;32m      2\u001b[0m     \u001b[0mnum_traces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mobserve_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'obs0'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'dim'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'depth'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;32m/scratch/mdd424/CGinkgo/lib/python3.7/site-packages/pyprob/model.py\u001b[0m in \u001b[0;36mlearn_inference_network\u001b[0;34m(self, num_traces, num_traces_end, inference_network, prior_inflation, dataset_dir, dataset_valid_dir, observe_embeddings, batch_size, valid_size, valid_every, optimizer_type, learning_rate_init, learning_rate_end, learning_rate_scheduler_type, momentum, weight_decay, save_file_name_prefix, save_every_sec, pre_generate_layers, distributed_backend, distributed_params_sync_every_iter, distributed_num_buckets, dataloader_offline_num_workers, stop_with_bad_loss, log_file_name, lstm_dim, lstm_depth, proposal_mixture_components)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_traces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_traces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_valid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_traces_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_traces_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_every\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate_scheduler_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate_scheduler_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_file_name_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_file_name_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_every_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_every_sec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed_backend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdistributed_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed_params_sync_every_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdistributed_params_sync_every_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed_num_buckets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdistributed_num_buckets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_offline_num_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataloader_offline_num_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_with_bad_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop_with_bad_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_file_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_inference_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mdd424/CGinkgo/lib/python3.7/site-packages/pyprob/nn/inference_network.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, num_traces, dataset, dataset_valid, num_traces_end, batch_size, valid_every, optimizer_type, learning_rate_init, learning_rate_end, learning_rate_scheduler_type, momentum, weight_decay, save_file_name_prefix, save_every_sec, distributed_backend, distributed_params_sync_every_iter, distributed_num_buckets, dataloader_offline_num_workers, stop_with_bad_loss, log_file_name)\u001b[0m\n\u001b[1;32m    476\u001b[0m                     \u001b[0mlayers_changed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m                     \u001b[0mlayers_changed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_polymorph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlayers_changed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mdd424/CGinkgo/lib/python3.7/site-packages/pyprob/nn/inference_network_feedforward.py\u001b[0m in \u001b[0;36m_polymorph\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     37\u001b[0m                         \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProposalCategoricalCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_observe_embedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_categories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Distribution currently unsupported: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m                     \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers_proposal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Distribution currently unsupported: Exponential"
     ]
    }
   ],
   "source": [
    "model.learn_inference_network(\n",
    "    num_traces=10000,\n",
    "    observe_embeddings={'obs0': {'dim': 100, 'depth': 5}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
